import time
import random
import os
import requests
import speech_recognition as sr
import tempfile

# --- COQUI XTTS ---
from TTS.api import TTS
from playsound import playsound

# Sp√©cifiez ici le chemin de votre √©chantillon .wav pour la voix personnalis√©e
SPEAKER_WAV = "male_sample.wav"  # Changez par votre propre fichier si besoin

# Pr√©charge le mod√®le XTTS
tts_engine = TTS("tts_models/multilingual/multi-dataset/xtts_v2")

def safe_remove(filename):
    for _ in range(10):
        try:
            if os.path.exists(filename):
                os.remove(filename)
            break
        except PermissionError:
            time.sleep(0.2)

def speak(text):
    print(f"WillIAm üó£Ô∏è : {text}")
    print("Synth√®se en cours...")
    # Utilisation d'un fichier temporaire pour √©viter les soucis de permission
    with tempfile.NamedTemporaryFile(suffix=".wav", delete=False) as tmp:
        temp_path = tmp.name
    try:
        tts_engine.tts_to_file(
            text=text,
            file_path=temp_path,
            speaker_wav=SPEAKER_WAV,
            language="fr"
        )
    except Exception as e:
        print(f"Erreur XTTS : {e}")
        tts_engine.tts_to_file(
            text=text,
            file_path=temp_path,
            language="fr"
        )
    # Attendre que le fichier soit bien √©crit
    for _ in range(20):  # max 2 secondes
        if os.path.exists(temp_path) and os.path.getsize(temp_path) > 1024:
            break
        time.sleep(0.1)
    print("Lecture du fichier audio...")
    try:
        playsound(temp_path)
    except Exception as e:
        print(f"Erreur playsound : {e}")
    print("Lecture termin√©e.")
    safe_remove(temp_path)

def listen(timeout=8):
    recognizer = sr.Recognizer()
    with sr.Microphone() as source:
        recognizer.pause_threshold = 0.8
        recognizer.energy_threshold = 300
        try:
            print("üéôÔ∏è Parle, j'√©coute...")
            audio = recognizer.listen(source, timeout=timeout)
            query = recognizer.recognize_google(audio, language="fr-FR")
            print(f"üß† Tu as dit : {query}")
            return query
        except sr.WaitTimeoutError:
            print("‚åõ Aucun son d√©tect√©.")
            speak("Je n'ai rien entendu, peux-tu r√©p√©ter ?")
            return ""
        except sr.UnknownValueError:
            print("ü§î Je n'ai pas compris.")
            speak("Je n'ai pas compris, peux-tu r√©p√©ter ?")
            return ""
        except sr.RequestError:
            print("‚ùå Probl√®me de reconnaissance.")
            speak("Il y a un probl√®me de connexion avec la reconnaissance vocale.")
            return ""

def wait_for_wake_word(wake_words=None):
    if wake_words is None:
        wake_words = ["william", "bonjour william", "salut william"]
    recognizer = sr.Recognizer()
    with sr.Microphone() as source:
        recognizer.pause_threshold = 0.8
        recognizer.energy_threshold = 300
        while True:
            print(f"üéß En attente du mot d'activation : {', '.join(wake_words)} ...")
            try:
                audio = recognizer.listen(source, timeout=8)
                query = recognizer.recognize_google(audio, language="fr-FR")
                print(f"üß† (d√©tection) : {query}")
                for word in wake_words:
                    if word.lower() in query.lower():
                        speak("Oui, je t'√©coute !")
                        return
            except Exception:
                continue

def listen_until_sleep_word(sleep_words=None):
    if sleep_words is None:
        sleep_words = ["merci william", "au revoir", "stop", "bonne nuit", "dors william"]
    while True:
        phrase = listen()
        print("Phrase reconnue pour traitement :", repr(phrase))
        if not phrase:
            speak("Je n'ai pas compris, peux-tu r√©p√©ter ?")
            continue
        if any(word in phrase.lower() for word in sleep_words):
            speak("Tr√®s bien, je retourne en veille.")
            break
        yield phrase

def assistant_response(prompt, history=None, model="llama3"):
    """
    G√©n√®re une r√©ponse depuis Ollama (LLM local) avec gestion de l'historique.
    """
    messages = history[:] if history else []
    messages.append({"role": "user", "content": prompt})
    try:
        r = requests.post(
            "http://localhost:11434/api/chat",
            json={"model": model, "messages": messages},
            timeout=90
        )
        response = r.json()
        if "message" in response and "content" in response["message"]:
            return response["message"]["content"].strip()
        return "[Aucune r√©ponse g√©n√©r√©e par l'IA]"
    except Exception as e:
        print("Erreur Ollama:", e)
        return "Je rencontre un probl√®me pour r√©fl√©chir, d√©sol√©."

if __name__ == "__main__":
    speak("Bonjour, je suis WillIAm avec une voix masculine personnalis√©e et une intelligence augment√©e gr√¢ce √† l'IA Llama3 sur Ollama !")
    history = []
    while True:
        wait_for_wake_word()
        for phrase in listen_until_sleep_word():
            print("Phrase re√ßue :", phrase)
            rep = assistant_response(phrase, history)
            history.append({"role": "user", "content": phrase})
            history.append({"role": "assistant", "content": rep})
            speak(rep)